{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42) #in case we will use random somewhere\n",
    "\n",
    "data = pd.read_csv(\"../data/processed/processed_credit_risk_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y = data['loan_status'].values\n",
    "X = data.drop(columns=['loan_status']).values  # Converting data to NumPy array\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32) # Converting to PyTorch tensors\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into PyTorch datasets\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditRiskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CreditRiskModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(X.shape[1], 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CreditRiskModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.3273\n",
      "Epoch 2/100, Loss: 0.2836\n",
      "Epoch 3/100, Loss: 0.2737\n",
      "Epoch 4/100, Loss: 0.2669\n",
      "Epoch 5/100, Loss: 0.2622\n",
      "Epoch 6/100, Loss: 0.2591\n",
      "Epoch 7/100, Loss: 0.2565\n",
      "Epoch 8/100, Loss: 0.2537\n",
      "Epoch 9/100, Loss: 0.2523\n",
      "Epoch 10/100, Loss: 0.2512\n",
      "Epoch 11/100, Loss: 0.2497\n",
      "Epoch 12/100, Loss: 0.2480\n",
      "Epoch 13/100, Loss: 0.2467\n",
      "Epoch 14/100, Loss: 0.2445\n",
      "Epoch 15/100, Loss: 0.2443\n",
      "Epoch 16/100, Loss: 0.2429\n",
      "Epoch 17/100, Loss: 0.2413\n",
      "Epoch 18/100, Loss: 0.2396\n",
      "Epoch 19/100, Loss: 0.2396\n",
      "Epoch 20/100, Loss: 0.2382\n",
      "Epoch 21/100, Loss: 0.2372\n",
      "Epoch 22/100, Loss: 0.2348\n",
      "Epoch 23/100, Loss: 0.2343\n",
      "Epoch 24/100, Loss: 0.2327\n",
      "Epoch 25/100, Loss: 0.2322\n",
      "Epoch 26/100, Loss: 0.2312\n",
      "Epoch 27/100, Loss: 0.2287\n",
      "Epoch 28/100, Loss: 0.2277\n",
      "Epoch 29/100, Loss: 0.2265\n",
      "Epoch 30/100, Loss: 0.2249\n",
      "Epoch 31/100, Loss: 0.2228\n",
      "Epoch 32/100, Loss: 0.2217\n",
      "Epoch 33/100, Loss: 0.2204\n",
      "Epoch 34/100, Loss: 0.2192\n",
      "Epoch 35/100, Loss: 0.2183\n",
      "Epoch 36/100, Loss: 0.2183\n",
      "Epoch 37/100, Loss: 0.2148\n",
      "Epoch 38/100, Loss: 0.2141\n",
      "Epoch 39/100, Loss: 0.2121\n",
      "Epoch 40/100, Loss: 0.2125\n",
      "Epoch 41/100, Loss: 0.2114\n",
      "Epoch 42/100, Loss: 0.2088\n",
      "Epoch 43/100, Loss: 0.2092\n",
      "Epoch 44/100, Loss: 0.2068\n",
      "Epoch 45/100, Loss: 0.2078\n",
      "Epoch 46/100, Loss: 0.2046\n",
      "Epoch 47/100, Loss: 0.2041\n",
      "Epoch 48/100, Loss: 0.2019\n",
      "Epoch 49/100, Loss: 0.2012\n",
      "Epoch 50/100, Loss: 0.2031\n",
      "Epoch 51/100, Loss: 0.2006\n",
      "Epoch 52/100, Loss: 0.1999\n",
      "Epoch 53/100, Loss: 0.1977\n",
      "Epoch 54/100, Loss: 0.1977\n",
      "Epoch 55/100, Loss: 0.1969\n",
      "Epoch 56/100, Loss: 0.1947\n",
      "Epoch 57/100, Loss: 0.1929\n",
      "Epoch 58/100, Loss: 0.1933\n",
      "Epoch 59/100, Loss: 0.1926\n",
      "Epoch 60/100, Loss: 0.1933\n",
      "Epoch 61/100, Loss: 0.1906\n",
      "Epoch 62/100, Loss: 0.1906\n",
      "Epoch 63/100, Loss: 0.1913\n",
      "Epoch 64/100, Loss: 0.1894\n",
      "Epoch 65/100, Loss: 0.1880\n",
      "Epoch 66/100, Loss: 0.1855\n",
      "Epoch 67/100, Loss: 0.1852\n",
      "Epoch 68/100, Loss: 0.1853\n",
      "Epoch 69/100, Loss: 0.1816\n",
      "Epoch 70/100, Loss: 0.1838\n",
      "Epoch 71/100, Loss: 0.1821\n",
      "Epoch 72/100, Loss: 0.1792\n",
      "Epoch 73/100, Loss: 0.1817\n",
      "Epoch 74/100, Loss: 0.1795\n",
      "Epoch 75/100, Loss: 0.1777\n",
      "Epoch 76/100, Loss: 0.1780\n",
      "Epoch 77/100, Loss: 0.1797\n",
      "Epoch 78/100, Loss: 0.1761\n",
      "Epoch 79/100, Loss: 0.1793\n",
      "Epoch 80/100, Loss: 0.1737\n",
      "Epoch 81/100, Loss: 0.1742\n",
      "Epoch 82/100, Loss: 0.1729\n",
      "Epoch 83/100, Loss: 0.1717\n",
      "Epoch 84/100, Loss: 0.1764\n",
      "Epoch 85/100, Loss: 0.1708\n",
      "Epoch 86/100, Loss: 0.1710\n",
      "Epoch 87/100, Loss: 0.1694\n",
      "Epoch 88/100, Loss: 0.1686\n",
      "Epoch 89/100, Loss: 0.1670\n",
      "Epoch 90/100, Loss: 0.1665\n",
      "Epoch 91/100, Loss: 0.1669\n",
      "Epoch 92/100, Loss: 0.1686\n",
      "Epoch 93/100, Loss: 0.1657\n",
      "Epoch 94/100, Loss: 0.1635\n",
      "Epoch 95/100, Loss: 0.1639\n",
      "Epoch 96/100, Loss: 0.1619\n",
      "Epoch 97/100, Loss: 0.1610\n",
      "Epoch 98/100, Loss: 0.1675\n",
      "Epoch 99/100, Loss: 0.1690\n",
      "Epoch 100/100, Loss: 0.1618\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        y_pred.append(outputs)\n",
    "\n",
    "y_pred = torch.cat(y_pred).numpy()\n",
    "y_pred = (y_pred >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.893355838576032\n",
      "\n",
      "Confusion Matrix: \n",
      " [[4851  221]\n",
      " [ 474  971]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.93      5072\n",
      "         1.0       0.81      0.67      0.74      1445\n",
      "\n",
      "    accuracy                           0.89      6517\n",
      "   macro avg       0.86      0.81      0.83      6517\n",
      "weighted avg       0.89      0.89      0.89      6517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results from PyTorch model show a significant improvement over the Keras model you previously trained\n",
    "# Accuracy indicates that the model correctly predicts the loan status about 89% of the time, which is a good overall performance.\n",
    "# F1 Score is good for 0 class 0.93, but worse for 1 class 0.78. But it still better than Keras model.\n",
    "# Class 0 is predicted with higher accuracy, precision, and recall, indicating the model is more confident in identifying non-default cases.\n",
    "# Class 1 has lower recall, meaning the model misses a portion of actual defaults, which is a common issue in imbalanced datasets like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/credit_risk_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
