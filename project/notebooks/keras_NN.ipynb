{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import pandas as pd \n",
    "import random \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42) #in case we will use random somewhere\n",
    "\n",
    "data = pd.read_csv(\"../data/processed/processed_credit_risk_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['loan_status']\n",
    "X = data.drop('loan_status',axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state= 42) #stratify to handle imbalance in target lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3), # Dropout layer to prevent overfitting \n",
    "    Dense(1, activation='sigmoid') # Output layer for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,841</span> (15.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,841\u001b[0m (15.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,841</span> (15.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,841\u001b[0m (15.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 836us/step - accuracy: 0.6771 - loss: 173.3493 - val_accuracy: 0.7823 - val_loss: 1.8633\n",
      "Epoch 2/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.7822 - loss: 2.2094 - val_accuracy: 0.7822 - val_loss: 0.7867\n",
      "Epoch 3/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.7756 - loss: 0.6290 - val_accuracy: 0.7820 - val_loss: 0.5262\n",
      "Epoch 4/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.7838 - loss: 0.6071 - val_accuracy: 0.7820 - val_loss: 0.5249\n",
      "Epoch 5/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7787 - loss: 0.5289 - val_accuracy: 0.7820 - val_loss: 0.5244\n",
      "Epoch 6/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7776 - loss: 0.5405 - val_accuracy: 0.7820 - val_loss: 0.5243\n",
      "Epoch 7/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7822 - loss: 0.5240 - val_accuracy: 0.7820 - val_loss: 0.5237\n",
      "Epoch 8/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.7833 - loss: 0.5217 - val_accuracy: 0.7822 - val_loss: 0.5224\n",
      "Epoch 9/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.7831 - loss: 0.5225 - val_accuracy: 0.7838 - val_loss: 0.5211\n",
      "Epoch 10/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.7814 - loss: 0.5314 - val_accuracy: 0.7847 - val_loss: 0.5184\n",
      "Epoch 11/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.7872 - loss: 0.5159 - val_accuracy: 0.7843 - val_loss: 0.5191\n",
      "Epoch 12/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.7804 - loss: 0.5249 - val_accuracy: 0.7837 - val_loss: 0.5209\n",
      "Epoch 13/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.7862 - loss: 0.5198 - val_accuracy: 0.7846 - val_loss: 0.5185\n",
      "Epoch 14/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7884 - loss: 0.5139 - val_accuracy: 0.7865 - val_loss: 0.5155\n",
      "Epoch 15/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7826 - loss: 0.5449 - val_accuracy: 0.7820 - val_loss: 0.5243\n",
      "Epoch 16/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.7796 - loss: 0.5275 - val_accuracy: 0.7820 - val_loss: 0.5243\n",
      "Epoch 17/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.7834 - loss: 0.5225 - val_accuracy: 0.7822 - val_loss: 0.5240\n",
      "Epoch 18/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.7835 - loss: 0.5575 - val_accuracy: 0.7822 - val_loss: 0.5241\n",
      "Epoch 19/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7826 - loss: 0.5235 - val_accuracy: 0.7823 - val_loss: 0.5240\n",
      "Epoch 20/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7826 - loss: 0.5236 - val_accuracy: 0.7822 - val_loss: 0.5238\n",
      "Epoch 21/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7818 - loss: 0.5835 - val_accuracy: 0.7820 - val_loss: 0.5241\n",
      "Epoch 22/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.7840 - loss: 0.5216 - val_accuracy: 0.7822 - val_loss: 0.5237\n",
      "Epoch 23/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7821 - loss: 0.5240 - val_accuracy: 0.7827 - val_loss: 0.5232\n",
      "Epoch 24/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.7815 - loss: 0.5303 - val_accuracy: 0.7837 - val_loss: 0.5222\n",
      "Epoch 25/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7842 - loss: 0.5215 - val_accuracy: 0.7841 - val_loss: 0.5218\n",
      "Epoch 26/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7777 - loss: 0.5294 - val_accuracy: 0.7837 - val_loss: 0.5219\n",
      "Epoch 27/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.7834 - loss: 0.5249 - val_accuracy: 0.7827 - val_loss: 0.5229\n",
      "Epoch 28/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.7854 - loss: 0.5196 - val_accuracy: 0.7836 - val_loss: 0.5223\n",
      "Epoch 29/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7818 - loss: 0.5260 - val_accuracy: 0.7842 - val_loss: 0.5213\n",
      "Epoch 30/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7856 - loss: 0.5249 - val_accuracy: 0.7838 - val_loss: 0.5216\n",
      "Epoch 31/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7826 - loss: 0.5237 - val_accuracy: 0.7838 - val_loss: 0.5209\n",
      "Epoch 32/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.7800 - loss: 0.5264 - val_accuracy: 0.7844 - val_loss: 0.5207\n",
      "Epoch 33/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.7832 - loss: 0.5226 - val_accuracy: 0.7827 - val_loss: 0.5236\n",
      "Epoch 34/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.7832 - loss: 0.5228 - val_accuracy: 0.7823 - val_loss: 0.5235\n",
      "Epoch 35/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.7824 - loss: 0.5248 - val_accuracy: 0.7826 - val_loss: 0.5230\n",
      "Epoch 36/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7792 - loss: 0.5271 - val_accuracy: 0.7838 - val_loss: 0.5220\n",
      "Epoch 37/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7873 - loss: 0.5175 - val_accuracy: 0.7841 - val_loss: 0.5212\n",
      "Epoch 38/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7845 - loss: 0.5204 - val_accuracy: 0.7843 - val_loss: 0.5205\n",
      "Epoch 39/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7823 - loss: 0.5237 - val_accuracy: 0.7852 - val_loss: 0.5198\n",
      "Epoch 40/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.7834 - loss: 0.5347 - val_accuracy: 0.7839 - val_loss: 0.5220\n",
      "Epoch 41/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7820 - loss: 0.5711 - val_accuracy: 0.7828 - val_loss: 0.5234\n",
      "Epoch 42/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7824 - loss: 0.5235 - val_accuracy: 0.7841 - val_loss: 0.5221\n",
      "Epoch 43/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.7810 - loss: 0.5262 - val_accuracy: 0.7839 - val_loss: 0.5206\n",
      "Epoch 44/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.7805 - loss: 0.5256 - val_accuracy: 0.7841 - val_loss: 0.5212\n",
      "Epoch 45/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - accuracy: 0.7877 - loss: 0.5170 - val_accuracy: 0.7826 - val_loss: 0.5233\n",
      "Epoch 46/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7820 - loss: 0.5896 - val_accuracy: 0.7835 - val_loss: 0.5224\n",
      "Epoch 47/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7815 - loss: 0.5663 - val_accuracy: 0.7839 - val_loss: 0.5215\n",
      "Epoch 48/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.7836 - loss: 0.5220 - val_accuracy: 0.7842 - val_loss: 0.5211\n",
      "Epoch 49/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.7886 - loss: 0.5156 - val_accuracy: 0.7844 - val_loss: 0.5205\n",
      "Epoch 50/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.7764 - loss: 0.5308 - val_accuracy: 0.7838 - val_loss: 0.5191\n",
      "Epoch 51/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.7816 - loss: 0.5246 - val_accuracy: 0.7842 - val_loss: 0.5212\n",
      "Epoch 52/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.7814 - loss: 0.5244 - val_accuracy: 0.7849 - val_loss: 0.5204\n",
      "Epoch 53/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.7856 - loss: 0.5193 - val_accuracy: 0.7827 - val_loss: 0.5235\n",
      "Epoch 54/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.7826 - loss: 0.5229 - val_accuracy: 0.7853 - val_loss: 0.5181\n",
      "Epoch 55/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7867 - loss: 0.5152 - val_accuracy: 0.7879 - val_loss: 0.5123\n",
      "Epoch 56/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.7867 - loss: 0.5150 - val_accuracy: 0.7879 - val_loss: 0.5134\n",
      "Epoch 57/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.7879 - loss: 0.5164 - val_accuracy: 0.7871 - val_loss: 0.5143\n",
      "Epoch 58/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.7885 - loss: 0.5141 - val_accuracy: 0.7839 - val_loss: 0.5221\n",
      "Epoch 59/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7854 - loss: 0.5200 - val_accuracy: 0.7841 - val_loss: 0.5211\n",
      "Epoch 60/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.7796 - loss: 0.5269 - val_accuracy: 0.7849 - val_loss: 0.5203\n",
      "Epoch 61/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7828 - loss: 0.5247 - val_accuracy: 0.7848 - val_loss: 0.5201\n",
      "Epoch 62/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.7872 - loss: 0.6049 - val_accuracy: 0.7871 - val_loss: 0.5151\n",
      "Epoch 63/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7907 - loss: 0.5104 - val_accuracy: 0.7903 - val_loss: 0.5096\n",
      "Epoch 64/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7857 - loss: 0.5156 - val_accuracy: 0.7892 - val_loss: 0.6304\n",
      "Epoch 65/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.7897 - loss: 0.5119 - val_accuracy: 0.7882 - val_loss: 0.5114\n",
      "Epoch 66/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.7919 - loss: 0.5094 - val_accuracy: 0.7890 - val_loss: 0.5111\n",
      "Epoch 67/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.7881 - loss: 0.8946 - val_accuracy: 0.7886 - val_loss: 0.5110\n",
      "Epoch 68/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7783 - loss: 0.5258 - val_accuracy: 0.7862 - val_loss: 0.5178\n",
      "Epoch 69/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7814 - loss: 0.5568 - val_accuracy: 0.7848 - val_loss: 0.5203\n",
      "Epoch 70/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7870 - loss: 0.5174 - val_accuracy: 0.7854 - val_loss: 0.5189\n",
      "Epoch 71/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.7827 - loss: 0.5293 - val_accuracy: 0.7842 - val_loss: 0.5206\n",
      "Epoch 72/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7857 - loss: 0.5187 - val_accuracy: 0.7854 - val_loss: 0.5191\n",
      "Epoch 73/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7863 - loss: 0.5184 - val_accuracy: 0.7904 - val_loss: 0.5111\n",
      "Epoch 74/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.7872 - loss: 0.5155 - val_accuracy: 0.7881 - val_loss: 0.5135\n",
      "Epoch 75/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.7888 - loss: 0.5129 - val_accuracy: 0.7898 - val_loss: 0.5095\n",
      "Epoch 76/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.7898 - loss: 0.5093 - val_accuracy: 0.7825 - val_loss: 0.5234\n",
      "Epoch 77/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7799 - loss: 0.5294 - val_accuracy: 0.7838 - val_loss: 0.5222\n",
      "Epoch 78/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7852 - loss: 0.5200 - val_accuracy: 0.7848 - val_loss: 0.5206\n",
      "Epoch 79/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7849 - loss: 0.5206 - val_accuracy: 0.7848 - val_loss: 0.5198\n",
      "Epoch 80/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.7857 - loss: 0.5221 - val_accuracy: 0.7847 - val_loss: 0.5197\n",
      "Epoch 81/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7876 - loss: 0.5160 - val_accuracy: 0.7838 - val_loss: 0.5220\n",
      "Epoch 82/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.7818 - loss: 0.5249 - val_accuracy: 0.7848 - val_loss: 0.5566\n",
      "Epoch 83/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - accuracy: 0.7793 - loss: 0.5504 - val_accuracy: 0.7846 - val_loss: 0.5207\n",
      "Epoch 84/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.7859 - loss: 0.5193 - val_accuracy: 0.7847 - val_loss: 0.5204\n",
      "Epoch 85/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.7871 - loss: 0.5181 - val_accuracy: 0.7838 - val_loss: 0.5217\n",
      "Epoch 86/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.7845 - loss: 0.5261 - val_accuracy: 0.7846 - val_loss: 0.5209\n",
      "Epoch 87/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.7842 - loss: 0.5212 - val_accuracy: 0.7852 - val_loss: 0.5200\n",
      "Epoch 88/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.7879 - loss: 0.5178 - val_accuracy: 0.7848 - val_loss: 0.5202\n",
      "Epoch 89/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.7827 - loss: 0.5228 - val_accuracy: 0.7874 - val_loss: 0.5162\n",
      "Epoch 90/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7881 - loss: 0.5145 - val_accuracy: 0.7887 - val_loss: 0.5110\n",
      "Epoch 91/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.7810 - loss: 0.5233 - val_accuracy: 0.7871 - val_loss: 0.5152\n",
      "Epoch 92/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.7813 - loss: 0.5252 - val_accuracy: 0.7848 - val_loss: 0.5212\n",
      "Epoch 93/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.7852 - loss: 0.5203 - val_accuracy: 0.7855 - val_loss: 0.5193\n",
      "Epoch 94/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7873 - loss: 0.5171 - val_accuracy: 0.7890 - val_loss: 0.5111\n",
      "Epoch 95/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.7935 - loss: 0.5075 - val_accuracy: 0.7837 - val_loss: 0.5223\n",
      "Epoch 96/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.7844 - loss: 0.5238 - val_accuracy: 0.7843 - val_loss: 0.5213\n",
      "Epoch 97/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7803 - loss: 0.5256 - val_accuracy: 0.7847 - val_loss: 0.5203\n",
      "Epoch 98/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.7862 - loss: 0.5187 - val_accuracy: 0.7850 - val_loss: 0.5207\n",
      "Epoch 99/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.7851 - loss: 0.5200 - val_accuracy: 0.7848 - val_loss: 0.5201\n",
      "Epoch 100/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7798 - loss: 0.5267 - val_accuracy: 0.7884 - val_loss: 0.5126\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7870 - loss: 0.5632 - val_accuracy: 0.7849 - val_loss: 0.5203\n",
      "Epoch 2/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7846 - loss: 0.5209 - val_accuracy: 0.7843 - val_loss: 0.5206\n",
      "Epoch 3/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.7858 - loss: 0.5189 - val_accuracy: 0.7859 - val_loss: 0.5191\n",
      "Epoch 4/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.7871 - loss: 0.5171 - val_accuracy: 0.7855 - val_loss: 0.5174\n",
      "Epoch 5/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7811 - loss: 0.5240 - val_accuracy: 0.7898 - val_loss: 0.5096\n",
      "Epoch 6/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.7851 - loss: 0.5193 - val_accuracy: 0.7849 - val_loss: 0.5209\n",
      "Epoch 7/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7870 - loss: 0.5174 - val_accuracy: 0.7849 - val_loss: 0.5204\n",
      "Epoch 8/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.7861 - loss: 0.5190 - val_accuracy: 0.7858 - val_loss: 0.5201\n",
      "Epoch 9/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7864 - loss: 0.5186 - val_accuracy: 0.7879 - val_loss: 0.5144\n",
      "Epoch 10/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.7875 - loss: 0.5134 - val_accuracy: 0.7857 - val_loss: 0.5337\n",
      "Epoch 11/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.7834 - loss: 0.9095 - val_accuracy: 0.7864 - val_loss: 0.5188\n",
      "Epoch 12/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7863 - loss: 0.5201 - val_accuracy: 0.7839 - val_loss: 1.5480\n",
      "Epoch 13/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.7876 - loss: 0.9475 - val_accuracy: 0.7853 - val_loss: 0.5192\n",
      "Epoch 14/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.7892 - loss: 0.5143 - val_accuracy: 0.7849 - val_loss: 0.5182\n",
      "Epoch 15/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7821 - loss: 0.5227 - val_accuracy: 0.7902 - val_loss: 0.5083\n",
      "Epoch 16/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.7839 - loss: 0.5263 - val_accuracy: 0.7852 - val_loss: 0.5207\n",
      "Epoch 17/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.7883 - loss: 0.6249 - val_accuracy: 0.7839 - val_loss: 0.5218\n",
      "Epoch 18/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.7862 - loss: 0.5296 - val_accuracy: 0.7855 - val_loss: 0.5209\n",
      "Epoch 19/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.7838 - loss: 0.5225 - val_accuracy: 0.7864 - val_loss: 0.5183\n",
      "Epoch 20/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7843 - loss: 0.5212 - val_accuracy: 0.7863 - val_loss: 0.5175\n",
      "Epoch 21/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.7880 - loss: 0.5137 - val_accuracy: 0.7871 - val_loss: 0.5168\n",
      "Epoch 22/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.7837 - loss: 0.5210 - val_accuracy: 0.7898 - val_loss: 0.5079\n",
      "Epoch 23/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.7895 - loss: 0.5123 - val_accuracy: 0.7862 - val_loss: 0.5186\n",
      "Epoch 24/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.7849 - loss: 0.5191 - val_accuracy: 0.7857 - val_loss: 0.5204\n",
      "Epoch 25/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7903 - loss: 0.5125 - val_accuracy: 0.7846 - val_loss: 0.5197\n",
      "Epoch 26/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7868 - loss: 0.5171 - val_accuracy: 0.7939 - val_loss: 0.5032\n",
      "Epoch 27/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.7917 - loss: 0.5114 - val_accuracy: 0.7854 - val_loss: 0.5201\n",
      "Epoch 28/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.7849 - loss: 0.5210 - val_accuracy: 0.7868 - val_loss: 0.5199\n",
      "Epoch 29/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7809 - loss: 0.5290 - val_accuracy: 0.7855 - val_loss: 0.5197\n",
      "Epoch 30/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7842 - loss: 0.5209 - val_accuracy: 0.7863 - val_loss: 0.5181\n",
      "Epoch 31/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.7872 - loss: 0.5156 - val_accuracy: 0.7871 - val_loss: 0.5166\n",
      "Epoch 32/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.7895 - loss: 0.5126 - val_accuracy: 0.7891 - val_loss: 0.5116\n",
      "Epoch 33/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.7868 - loss: 0.5181 - val_accuracy: 0.7875 - val_loss: 0.5184\n",
      "Epoch 34/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.7869 - loss: 0.5170 - val_accuracy: 0.7885 - val_loss: 0.5147\n",
      "Epoch 35/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.7873 - loss: 0.5154 - val_accuracy: 0.7853 - val_loss: 0.5210\n",
      "Epoch 36/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7859 - loss: 0.5194 - val_accuracy: 0.7863 - val_loss: 0.5194\n",
      "Epoch 37/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7871 - loss: 0.5174 - val_accuracy: 0.7848 - val_loss: 0.5215\n",
      "Epoch 38/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.7869 - loss: 0.5175 - val_accuracy: 0.7874 - val_loss: 0.5183\n",
      "Epoch 39/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.7913 - loss: 0.5113 - val_accuracy: 0.7855 - val_loss: 0.5201\n",
      "Epoch 40/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.7860 - loss: 0.5183 - val_accuracy: 0.7884 - val_loss: 0.5153\n",
      "Epoch 41/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.7828 - loss: 0.5238 - val_accuracy: 0.7896 - val_loss: 0.5099\n",
      "Epoch 42/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.7857 - loss: 0.5187 - val_accuracy: 0.7885 - val_loss: 0.5098\n",
      "Epoch 43/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7893 - loss: 0.5150 - val_accuracy: 0.7869 - val_loss: 0.5188\n",
      "Epoch 44/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.7864 - loss: 0.5190 - val_accuracy: 0.7887 - val_loss: 0.5149\n",
      "Epoch 45/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7888 - loss: 0.5143 - val_accuracy: 0.7898 - val_loss: 0.5098\n",
      "Epoch 46/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7867 - loss: 0.5180 - val_accuracy: 0.7865 - val_loss: 0.5190\n",
      "Epoch 47/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7854 - loss: 0.5194 - val_accuracy: 0.7886 - val_loss: 0.5128\n",
      "Epoch 48/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.7901 - loss: 0.5126 - val_accuracy: 0.7907 - val_loss: 0.5070\n",
      "Epoch 49/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.7883 - loss: 0.5156 - val_accuracy: 0.7884 - val_loss: 0.5156\n",
      "Epoch 50/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.7908 - loss: 0.5119 - val_accuracy: 0.7846 - val_loss: 0.5206\n",
      "Epoch 51/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.7808 - loss: 0.5253 - val_accuracy: 0.7886 - val_loss: 0.5154\n",
      "Epoch 52/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.7859 - loss: 0.5182 - val_accuracy: 0.7881 - val_loss: 0.5167\n",
      "Epoch 53/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.7867 - loss: 0.5172 - val_accuracy: 0.7902 - val_loss: 0.5107\n",
      "Epoch 54/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.7934 - loss: 0.5079 - val_accuracy: 0.7860 - val_loss: 0.5182\n",
      "Epoch 55/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7874 - loss: 0.5173 - val_accuracy: 0.7850 - val_loss: 0.5202\n",
      "Epoch 56/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.7856 - loss: 0.5194 - val_accuracy: 0.7889 - val_loss: 0.5149\n",
      "Epoch 57/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.7909 - loss: 0.5109 - val_accuracy: 0.7858 - val_loss: 0.5200\n",
      "Epoch 58/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.7868 - loss: 0.5180 - val_accuracy: 0.7906 - val_loss: 0.5114\n",
      "Epoch 59/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7886 - loss: 0.5136 - val_accuracy: 0.7853 - val_loss: 0.5188\n",
      "Epoch 60/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.7883 - loss: 0.5146 - val_accuracy: 0.7903 - val_loss: 0.5114\n",
      "Epoch 61/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.7874 - loss: 0.5155 - val_accuracy: 0.7887 - val_loss: 0.5174\n",
      "Epoch 62/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.7933 - loss: 0.5093 - val_accuracy: 0.7884 - val_loss: 0.5174\n",
      "Epoch 63/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.7860 - loss: 0.5190 - val_accuracy: 0.7918 - val_loss: 0.5091\n",
      "Epoch 64/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7918 - loss: 0.6089 - val_accuracy: 0.7868 - val_loss: 0.5186\n",
      "Epoch 65/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7860 - loss: 0.5178 - val_accuracy: 0.7866 - val_loss: 0.5160\n",
      "Epoch 66/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7930 - loss: 0.5070 - val_accuracy: 0.7904 - val_loss: 0.5093\n",
      "Epoch 67/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.7886 - loss: 0.5123 - val_accuracy: 0.7843 - val_loss: 0.5212\n",
      "Epoch 68/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.7868 - loss: 0.5200 - val_accuracy: 0.7897 - val_loss: 0.5114\n",
      "Epoch 69/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.7914 - loss: 0.5085 - val_accuracy: 0.7893 - val_loss: 0.5142\n",
      "Epoch 70/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.7873 - loss: 0.5158 - val_accuracy: 0.7873 - val_loss: 0.5198\n",
      "Epoch 71/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.7817 - loss: 0.5298 - val_accuracy: 0.7832 - val_loss: 0.5233\n",
      "Epoch 72/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.7805 - loss: 0.5266 - val_accuracy: 0.7859 - val_loss: 0.5196\n",
      "Epoch 73/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.7894 - loss: 0.5140 - val_accuracy: 0.7891 - val_loss: 0.5145\n",
      "Epoch 74/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.7882 - loss: 0.5150 - val_accuracy: 0.7874 - val_loss: 0.5181\n",
      "Epoch 75/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.7887 - loss: 1.7486 - val_accuracy: 0.7873 - val_loss: 0.5186\n",
      "Epoch 76/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7883 - loss: 0.5165 - val_accuracy: 0.7882 - val_loss: 0.5169\n",
      "Epoch 77/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7874 - loss: 0.5157 - val_accuracy: 0.7876 - val_loss: 0.5139\n",
      "Epoch 78/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.7900 - loss: 0.5115 - val_accuracy: 0.7877 - val_loss: 0.5165\n",
      "Epoch 79/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.7903 - loss: 0.5129 - val_accuracy: 0.7912 - val_loss: 0.5104\n",
      "Epoch 80/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.7907 - loss: 0.5107 - val_accuracy: 0.7871 - val_loss: 0.5166\n",
      "Epoch 81/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7928 - loss: 0.5085 - val_accuracy: 0.7908 - val_loss: 0.5100\n",
      "Epoch 82/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7878 - loss: 0.5152 - val_accuracy: 0.7887 - val_loss: 0.5156\n",
      "Epoch 83/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7946 - loss: 0.5075 - val_accuracy: 0.7865 - val_loss: 0.5189\n",
      "Epoch 84/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7861 - loss: 0.5822 - val_accuracy: 0.7889 - val_loss: 0.5142\n",
      "Epoch 85/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.7910 - loss: 0.5126 - val_accuracy: 0.7869 - val_loss: 0.5177\n",
      "Epoch 86/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7876 - loss: 0.5163 - val_accuracy: 0.7891 - val_loss: 0.5117\n",
      "Epoch 87/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.7888 - loss: 0.5140 - val_accuracy: 0.7922 - val_loss: 0.5087\n",
      "Epoch 88/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.7867 - loss: 0.5136 - val_accuracy: 0.7898 - val_loss: 0.5130\n",
      "Epoch 89/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.7923 - loss: 0.5090 - val_accuracy: 0.7902 - val_loss: 0.5120\n",
      "Epoch 90/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.7887 - loss: 0.5166 - val_accuracy: 0.7896 - val_loss: 0.5140\n",
      "Epoch 91/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7871 - loss: 0.5172 - val_accuracy: 0.7837 - val_loss: 0.5217\n",
      "Epoch 92/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 0.7865 - loss: 0.5179 - val_accuracy: 0.7889 - val_loss: 0.5143\n",
      "Epoch 93/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.7876 - loss: 0.5215 - val_accuracy: 0.7866 - val_loss: 0.5195\n",
      "Epoch 94/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.7807 - loss: 0.5270 - val_accuracy: 0.7854 - val_loss: 0.5198\n",
      "Epoch 95/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.7798 - loss: 0.5270 - val_accuracy: 0.7860 - val_loss: 0.5186\n",
      "Epoch 96/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.7880 - loss: 0.5167 - val_accuracy: 0.7865 - val_loss: 0.5172\n",
      "Epoch 97/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.7900 - loss: 0.5168 - val_accuracy: 0.7901 - val_loss: 0.5100\n",
      "Epoch 98/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.7849 - loss: 0.5212 - val_accuracy: 0.7877 - val_loss: 0.5188\n",
      "Epoch 99/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7877 - loss: 0.5173 - val_accuracy: 0.7849 - val_loss: 0.5213\n",
      "Epoch 100/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7841 - loss: 0.5210 - val_accuracy: 0.7864 - val_loss: 0.5180\n",
      "Epoch 101/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7899 - loss: 0.5167 - val_accuracy: 0.7862 - val_loss: 0.5193\n",
      "Epoch 102/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.7862 - loss: 0.5192 - val_accuracy: 0.7881 - val_loss: 0.5161\n",
      "Epoch 103/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.7887 - loss: 0.5143 - val_accuracy: 0.7873 - val_loss: 0.5200\n",
      "Epoch 104/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.7884 - loss: 0.5383 - val_accuracy: 0.7852 - val_loss: 0.5190\n",
      "Epoch 105/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.7842 - loss: 0.5207 - val_accuracy: 0.7885 - val_loss: 0.5135\n",
      "Epoch 106/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7902 - loss: 0.5190 - val_accuracy: 0.7863 - val_loss: 0.5277\n",
      "Epoch 107/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7980 - loss: 0.5035 - val_accuracy: 0.7909 - val_loss: 0.5128\n",
      "Epoch 108/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.7908 - loss: 0.5100 - val_accuracy: 0.7901 - val_loss: 0.5110\n",
      "Epoch 109/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.7904 - loss: 0.5129 - val_accuracy: 0.7859 - val_loss: 0.5191\n",
      "Epoch 110/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7875 - loss: 0.5169 - val_accuracy: 0.7874 - val_loss: 0.5184\n",
      "Epoch 111/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7865 - loss: 0.5172 - val_accuracy: 0.7859 - val_loss: 0.5201\n",
      "Epoch 112/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7855 - loss: 0.5197 - val_accuracy: 0.7879 - val_loss: 0.5175\n",
      "Epoch 113/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7846 - loss: 0.5207 - val_accuracy: 0.7916 - val_loss: 0.5103\n",
      "Epoch 114/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7874 - loss: 0.5180 - val_accuracy: 0.7860 - val_loss: 0.5199\n",
      "Epoch 115/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.7848 - loss: 0.5209 - val_accuracy: 0.7857 - val_loss: 0.5199\n",
      "Epoch 116/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7857 - loss: 0.5196 - val_accuracy: 0.7844 - val_loss: 0.5201\n",
      "Epoch 117/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7812 - loss: 0.5253 - val_accuracy: 0.7865 - val_loss: 0.5181\n",
      "Epoch 118/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.7874 - loss: 0.5167 - val_accuracy: 0.7866 - val_loss: 0.5174\n",
      "Epoch 119/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.7871 - loss: 0.5173 - val_accuracy: 0.7906 - val_loss: 0.5130\n",
      "Epoch 120/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.7872 - loss: 0.5185 - val_accuracy: 0.7886 - val_loss: 0.5149\n",
      "Epoch 121/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7919 - loss: 0.5099 - val_accuracy: 0.7839 - val_loss: 0.5231\n",
      "Epoch 122/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7875 - loss: 0.5171 - val_accuracy: 0.7852 - val_loss: 0.5206\n",
      "Epoch 123/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7836 - loss: 0.5220 - val_accuracy: 0.7853 - val_loss: 0.5203\n",
      "Epoch 124/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7850 - loss: 0.5202 - val_accuracy: 0.7927 - val_loss: 0.5099\n",
      "Epoch 125/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.7880 - loss: 0.5158 - val_accuracy: 0.7858 - val_loss: 0.5206\n",
      "Epoch 126/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7880 - loss: 0.5166 - val_accuracy: 0.7891 - val_loss: 0.5103\n",
      "Epoch 127/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.7916 - loss: 0.5187 - val_accuracy: 0.7881 - val_loss: 0.5130\n",
      "Epoch 128/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.7894 - loss: 0.5151 - val_accuracy: 0.7881 - val_loss: 0.5150\n",
      "Epoch 129/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7886 - loss: 0.5137 - val_accuracy: 0.7863 - val_loss: 0.5173\n",
      "Epoch 130/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.7851 - loss: 0.5197 - val_accuracy: 0.7865 - val_loss: 0.5178\n",
      "Epoch 131/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.7876 - loss: 0.5169 - val_accuracy: 0.7903 - val_loss: 0.5110\n",
      "Epoch 132/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7890 - loss: 0.5135 - val_accuracy: 0.7846 - val_loss: 0.5213\n",
      "Epoch 133/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7877 - loss: 0.5171 - val_accuracy: 0.7885 - val_loss: 0.5155\n",
      "Epoch 134/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7851 - loss: 0.5231 - val_accuracy: 0.7849 - val_loss: 0.5218\n",
      "Epoch 135/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.7842 - loss: 0.5214 - val_accuracy: 0.7879 - val_loss: 0.5168\n",
      "Epoch 136/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.7899 - loss: 0.5129 - val_accuracy: 0.7918 - val_loss: 0.5084\n",
      "Epoch 137/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.7909 - loss: 0.5109 - val_accuracy: 0.7864 - val_loss: 0.5180\n",
      "Epoch 138/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.7886 - loss: 0.5134 - val_accuracy: 0.7865 - val_loss: 0.5175\n",
      "Epoch 139/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.7899 - loss: 0.5157 - val_accuracy: 0.7870 - val_loss: 0.5181\n",
      "Epoch 140/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.7877 - loss: 0.5157 - val_accuracy: 0.7891 - val_loss: 0.5101\n",
      "Epoch 141/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.7907 - loss: 0.5094 - val_accuracy: 0.7900 - val_loss: 0.5118\n",
      "Epoch 142/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.7931 - loss: 0.5064 - val_accuracy: 0.7871 - val_loss: 0.5168\n",
      "Epoch 143/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7910 - loss: 0.5115 - val_accuracy: 0.7913 - val_loss: 0.5597\n",
      "Epoch 144/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.7860 - loss: 0.5240 - val_accuracy: 0.7876 - val_loss: 0.5171\n",
      "Epoch 145/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7900 - loss: 0.5240 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 146/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.7847 - loss: 0.5319 - val_accuracy: 0.7884 - val_loss: 0.5168\n",
      "Epoch 147/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.7833 - loss: 0.5213 - val_accuracy: 0.7865 - val_loss: 0.5186\n",
      "Epoch 148/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.7891 - loss: 0.5117 - val_accuracy: 0.7849 - val_loss: 0.5216\n",
      "Epoch 149/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7887 - loss: 0.5147 - val_accuracy: 0.7920 - val_loss: 0.5126\n",
      "Epoch 150/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.7934 - loss: 0.5077 - val_accuracy: 0.7900 - val_loss: 0.5115\n",
      "Epoch 151/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.7811 - loss: 0.5248 - val_accuracy: 0.7870 - val_loss: 0.5209\n",
      "Epoch 152/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.7872 - loss: 0.5172 - val_accuracy: 0.7914 - val_loss: 0.5123\n",
      "Epoch 153/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7895 - loss: 0.5224 - val_accuracy: 0.7868 - val_loss: 0.5220\n",
      "Epoch 154/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7851 - loss: 0.5201 - val_accuracy: 0.7897 - val_loss: 0.5177\n",
      "Epoch 155/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.7871 - loss: 0.5176 - val_accuracy: 0.7900 - val_loss: 0.5118\n",
      "Epoch 156/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7873 - loss: 0.5137 - val_accuracy: 0.7873 - val_loss: 0.5186\n",
      "Epoch 157/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.7897 - loss: 0.5138 - val_accuracy: 0.7873 - val_loss: 0.5296\n",
      "Epoch 158/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.7876 - loss: 0.5205 - val_accuracy: 0.7917 - val_loss: 0.5116\n",
      "Epoch 159/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7847 - loss: 0.5468 - val_accuracy: 0.7881 - val_loss: 0.5165\n",
      "Epoch 160/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7897 - loss: 0.5156 - val_accuracy: 0.7869 - val_loss: 0.5190\n",
      "Epoch 161/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.7878 - loss: 0.5169 - val_accuracy: 0.7893 - val_loss: 0.5192\n",
      "Epoch 162/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.7887 - loss: 0.5145 - val_accuracy: 0.7874 - val_loss: 0.5853\n",
      "Epoch 163/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7889 - loss: 0.5153 - val_accuracy: 0.7902 - val_loss: 0.5152\n",
      "Epoch 164/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.7913 - loss: 0.5108 - val_accuracy: 0.7924 - val_loss: 0.5718\n",
      "Epoch 165/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7842 - loss: 0.5182 - val_accuracy: 0.7917 - val_loss: 0.5103\n",
      "Epoch 166/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7940 - loss: 0.5123 - val_accuracy: 0.7863 - val_loss: 0.5176\n",
      "Epoch 167/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7864 - loss: 0.5180 - val_accuracy: 0.7895 - val_loss: 0.5179\n",
      "Epoch 168/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7868 - loss: 0.5254 - val_accuracy: 0.7885 - val_loss: 0.5155\n",
      "Epoch 169/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.7867 - loss: 0.5176 - val_accuracy: 0.7897 - val_loss: 0.5134\n",
      "Epoch 170/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.7888 - loss: 0.5140 - val_accuracy: 0.7898 - val_loss: 0.5138\n",
      "Epoch 171/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.7876 - loss: 0.5155 - val_accuracy: 0.7903 - val_loss: 0.5112\n",
      "Epoch 172/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.7911 - loss: 0.5117 - val_accuracy: 0.7902 - val_loss: 0.5128\n",
      "Epoch 173/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.7961 - loss: 0.5033 - val_accuracy: 0.7847 - val_loss: 0.5249\n",
      "Epoch 174/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7896 - loss: 0.5419 - val_accuracy: 0.7865 - val_loss: 0.5184\n",
      "Epoch 175/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7948 - loss: 0.5078 - val_accuracy: 0.7908 - val_loss: 0.5109\n",
      "Epoch 176/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.7895 - loss: 0.5126 - val_accuracy: 0.7876 - val_loss: 0.5175\n",
      "Epoch 177/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7903 - loss: 0.5122 - val_accuracy: 0.7893 - val_loss: 0.5140\n",
      "Epoch 178/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7868 - loss: 0.5173 - val_accuracy: 0.7886 - val_loss: 0.5165\n",
      "Epoch 179/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.7904 - loss: 0.5161 - val_accuracy: 0.7904 - val_loss: 0.5100\n",
      "Epoch 180/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.7873 - loss: 0.5162 - val_accuracy: 0.7902 - val_loss: 0.5126\n",
      "Epoch 181/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.7905 - loss: 0.5108 - val_accuracy: 0.7895 - val_loss: 0.5104\n",
      "Epoch 182/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.7871 - loss: 0.5144 - val_accuracy: 0.7919 - val_loss: 0.5081\n",
      "Epoch 183/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7908 - loss: 0.5185 - val_accuracy: 0.7898 - val_loss: 0.5160\n",
      "Epoch 184/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.7856 - loss: 0.5204 - val_accuracy: 0.7853 - val_loss: 0.5200\n",
      "Epoch 185/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7933 - loss: 0.5077 - val_accuracy: 0.7870 - val_loss: 0.5188\n",
      "Epoch 186/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 0.7858 - loss: 0.5211 - val_accuracy: 0.7897 - val_loss: 0.5184\n",
      "Epoch 187/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.7912 - loss: 0.5120 - val_accuracy: 0.7911 - val_loss: 0.5144\n",
      "Epoch 188/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7902 - loss: 0.5127 - val_accuracy: 0.7874 - val_loss: 0.5181\n",
      "Epoch 189/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.7878 - loss: 0.5157 - val_accuracy: 0.7914 - val_loss: 0.5103\n",
      "Epoch 190/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.7891 - loss: 0.5143 - val_accuracy: 0.7882 - val_loss: 0.5181\n",
      "Epoch 191/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 0.7921 - loss: 0.5114 - val_accuracy: 0.7857 - val_loss: 0.5199\n",
      "Epoch 192/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7822 - loss: 0.5248 - val_accuracy: 0.7891 - val_loss: 0.5162\n",
      "Epoch 193/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.7892 - loss: 0.5138 - val_accuracy: 0.7923 - val_loss: 0.5082\n",
      "Epoch 194/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.7909 - loss: 0.5136 - val_accuracy: 0.7870 - val_loss: 0.5193\n",
      "Epoch 195/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.7892 - loss: 0.5151 - val_accuracy: 0.7859 - val_loss: 0.5193\n",
      "Epoch 196/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7851 - loss: 0.5195 - val_accuracy: 0.7906 - val_loss: 0.5140\n",
      "Epoch 197/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.7854 - loss: 0.5183 - val_accuracy: 0.7902 - val_loss: 0.5139\n",
      "Epoch 198/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7938 - loss: 0.5080 - val_accuracy: 0.7922 - val_loss: 0.5163\n",
      "Epoch 199/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.7871 - loss: 0.5174 - val_accuracy: 0.7892 - val_loss: 0.5162\n",
      "Epoch 200/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7929 - loss: 0.5084 - val_accuracy: 0.7893 - val_loss: 0.5155\n",
      "Epoch 201/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.7886 - loss: 0.5204 - val_accuracy: 0.7864 - val_loss: 0.5201\n",
      "Epoch 202/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.7838 - loss: 0.5216 - val_accuracy: 0.7895 - val_loss: 0.5132\n",
      "Epoch 203/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.7923 - loss: 0.5097 - val_accuracy: 0.7895 - val_loss: 0.5158\n",
      "Epoch 204/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.7921 - loss: 0.5117 - val_accuracy: 0.7962 - val_loss: 0.5050\n",
      "Epoch 205/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.7829 - loss: 0.5275 - val_accuracy: 0.7879 - val_loss: 0.5143\n",
      "Epoch 206/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.7908 - loss: 0.5114 - val_accuracy: 0.7902 - val_loss: 0.5147\n",
      "Epoch 207/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.7875 - loss: 0.5149 - val_accuracy: 0.7912 - val_loss: 0.5112\n",
      "Epoch 208/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.7870 - loss: 0.5734 - val_accuracy: 0.7935 - val_loss: 0.5074\n",
      "Epoch 209/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.7904 - loss: 0.5107 - val_accuracy: 0.7923 - val_loss: 0.5094\n",
      "Epoch 210/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.7856 - loss: 0.5242 - val_accuracy: 0.7908 - val_loss: 0.5129\n",
      "Epoch 211/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7877 - loss: 0.5416 - val_accuracy: 0.7909 - val_loss: 0.5128\n",
      "Epoch 212/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.7934 - loss: 0.5082 - val_accuracy: 0.7949 - val_loss: 0.5040\n",
      "Epoch 213/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7894 - loss: 0.5132 - val_accuracy: 0.7904 - val_loss: 0.5118\n",
      "Epoch 214/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7954 - loss: 0.5046 - val_accuracy: 0.7870 - val_loss: 0.5175\n",
      "Epoch 215/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.7918 - loss: 0.5097 - val_accuracy: 0.7928 - val_loss: 0.5112\n",
      "Epoch 216/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7982 - loss: 0.5006 - val_accuracy: 0.7903 - val_loss: 0.5131\n",
      "Epoch 217/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7884 - loss: 0.5137 - val_accuracy: 0.7853 - val_loss: 0.5241\n",
      "Epoch 218/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.7915 - loss: 0.5098 - val_accuracy: 0.7860 - val_loss: 0.5207\n",
      "Epoch 219/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7872 - loss: 0.5165 - val_accuracy: 0.7945 - val_loss: 0.5082\n",
      "Epoch 220/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7887 - loss: 0.5132 - val_accuracy: 0.7930 - val_loss: 0.5087\n",
      "Epoch 221/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.5010 - val_accuracy: 0.7917 - val_loss: 0.5111\n",
      "Epoch 222/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7855 - loss: 0.5226 - val_accuracy: 0.7865 - val_loss: 0.5210\n",
      "Epoch 223/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.7899 - loss: 0.7196 - val_accuracy: 0.7914 - val_loss: 0.5128\n",
      "Epoch 224/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7920 - loss: 0.5107 - val_accuracy: 0.7923 - val_loss: 0.5093\n",
      "Epoch 225/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7886 - loss: 0.5113 - val_accuracy: 0.7890 - val_loss: 0.5159\n",
      "Epoch 226/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.7901 - loss: 0.5151 - val_accuracy: 0.7853 - val_loss: 0.5205\n",
      "Epoch 227/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - accuracy: 0.7883 - loss: 0.5147 - val_accuracy: 0.7941 - val_loss: 0.5097\n",
      "Epoch 228/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.7894 - loss: 0.5131 - val_accuracy: 0.7934 - val_loss: 0.5214\n",
      "Epoch 229/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.7866 - loss: 0.5221 - val_accuracy: 0.7954 - val_loss: 0.5071\n",
      "Epoch 230/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7928 - loss: 0.5081 - val_accuracy: 0.7936 - val_loss: 0.5088\n",
      "Epoch 231/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7917 - loss: 0.5097 - val_accuracy: 0.7920 - val_loss: 0.5161\n",
      "Epoch 232/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.7904 - loss: 0.5113 - val_accuracy: 0.7946 - val_loss: 0.5070\n",
      "Epoch 233/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.7935 - loss: 0.5050 - val_accuracy: 0.7873 - val_loss: 0.5138\n",
      "Epoch 234/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7923 - loss: 0.5076 - val_accuracy: 0.7970 - val_loss: 0.5008\n",
      "Epoch 235/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.7886 - loss: 0.5169 - val_accuracy: 0.7855 - val_loss: 0.5207\n",
      "Epoch 236/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7875 - loss: 0.5177 - val_accuracy: 0.7868 - val_loss: 0.5185\n",
      "Epoch 237/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7895 - loss: 0.5158 - val_accuracy: 0.7919 - val_loss: 0.5097\n",
      "Epoch 238/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.7870 - loss: 0.5168 - val_accuracy: 0.7938 - val_loss: 0.5074\n",
      "Epoch 239/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7923 - loss: 0.5096 - val_accuracy: 0.7916 - val_loss: 0.5126\n",
      "Epoch 240/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7950 - loss: 0.5051 - val_accuracy: 0.7891 - val_loss: 0.5152\n",
      "Epoch 241/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7902 - loss: 0.5121 - val_accuracy: 0.7881 - val_loss: 0.5186\n",
      "Epoch 242/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 0.7942 - loss: 0.5097 - val_accuracy: 0.7927 - val_loss: 0.5125\n",
      "Epoch 243/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7913 - loss: 0.5098 - val_accuracy: 0.7940 - val_loss: 0.5108\n",
      "Epoch 244/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7943 - loss: 0.5081 - val_accuracy: 0.7879 - val_loss: 0.5153\n",
      "Epoch 245/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7935 - loss: 0.5068 - val_accuracy: 0.7918 - val_loss: 0.5073\n",
      "Epoch 246/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7900 - loss: 0.5146 - val_accuracy: 0.7887 - val_loss: 0.5167\n",
      "Epoch 247/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.7868 - loss: 0.5173 - val_accuracy: 0.7918 - val_loss: 0.5094\n",
      "Epoch 248/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.7948 - loss: 0.5141 - val_accuracy: 0.7936 - val_loss: 0.5120\n",
      "Epoch 249/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.7965 - loss: 0.5036 - val_accuracy: 0.7944 - val_loss: 0.5076\n",
      "Epoch 250/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7951 - loss: 0.5058 - val_accuracy: 0.7920 - val_loss: 0.5129\n",
      "Epoch 251/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.7939 - loss: 0.5099 - val_accuracy: 0.7923 - val_loss: 0.5108\n",
      "Epoch 252/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7928 - loss: 0.5083 - val_accuracy: 0.7863 - val_loss: 0.5210\n",
      "Epoch 253/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7837 - loss: 0.5216 - val_accuracy: 0.7914 - val_loss: 0.5140\n",
      "Epoch 254/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.7897 - loss: 0.5131 - val_accuracy: 0.7928 - val_loss: 0.5114\n",
      "Epoch 255/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7906 - loss: 0.5195 - val_accuracy: 0.7895 - val_loss: 0.5171\n",
      "Epoch 256/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.7947 - loss: 0.5079 - val_accuracy: 0.7909 - val_loss: 0.5146\n",
      "Epoch 257/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.7893 - loss: 0.5136 - val_accuracy: 0.7941 - val_loss: 0.5083\n",
      "Epoch 258/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.7903 - loss: 0.5126 - val_accuracy: 0.7928 - val_loss: 0.5147\n",
      "Epoch 259/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.7939 - loss: 0.5097 - val_accuracy: 0.7893 - val_loss: 0.5181\n",
      "Epoch 260/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.7894 - loss: 0.5130 - val_accuracy: 0.7923 - val_loss: 0.5144\n",
      "Epoch 261/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.8005 - loss: 0.4985 - val_accuracy: 0.7908 - val_loss: 0.5120\n",
      "Epoch 262/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.7906 - loss: 0.5099 - val_accuracy: 0.7938 - val_loss: 0.5103\n",
      "Epoch 263/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7948 - loss: 0.5041 - val_accuracy: 0.8135 - val_loss: 0.4707\n",
      "Epoch 264/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.7909 - loss: 0.5121 - val_accuracy: 0.7904 - val_loss: 0.5169\n",
      "Epoch 265/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7888 - loss: 0.5151 - val_accuracy: 0.7933 - val_loss: 0.5143\n",
      "Epoch 266/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7873 - loss: 0.5242 - val_accuracy: 0.7927 - val_loss: 0.5083\n",
      "Epoch 267/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7938 - loss: 0.5079 - val_accuracy: 0.7882 - val_loss: 0.5163\n",
      "Epoch 268/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7880 - loss: 0.5172 - val_accuracy: 0.7936 - val_loss: 0.5056\n",
      "Epoch 269/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7930 - loss: 0.5383 - val_accuracy: 0.7922 - val_loss: 0.5093\n",
      "Epoch 270/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.7913 - loss: 0.5086 - val_accuracy: 0.7936 - val_loss: 0.5095\n",
      "Epoch 271/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.7960 - loss: 0.5040 - val_accuracy: 0.7951 - val_loss: 0.5087\n",
      "Epoch 272/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7967 - loss: 0.5070 - val_accuracy: 0.7881 - val_loss: 0.5162\n",
      "Epoch 273/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.7868 - loss: 0.5172 - val_accuracy: 0.7908 - val_loss: 0.5121\n",
      "Epoch 274/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.7879 - loss: 0.5154 - val_accuracy: 0.7868 - val_loss: 0.5141\n",
      "Epoch 275/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7951 - loss: 0.5041 - val_accuracy: 0.7903 - val_loss: 0.5110\n",
      "Epoch 276/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.7908 - loss: 0.5102 - val_accuracy: 0.7881 - val_loss: 0.5179\n",
      "Epoch 277/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7872 - loss: 0.5169 - val_accuracy: 0.7913 - val_loss: 0.5149\n",
      "Epoch 278/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7936 - loss: 0.5075 - val_accuracy: 0.7951 - val_loss: 0.5113\n",
      "Epoch 279/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.7920 - loss: 0.5072 - val_accuracy: 0.7927 - val_loss: 0.5088\n",
      "Epoch 280/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.7871 - loss: 0.5169 - val_accuracy: 0.7946 - val_loss: 0.5072\n",
      "Epoch 281/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.7935 - loss: 0.5065 - val_accuracy: 0.7930 - val_loss: 0.5113\n",
      "Epoch 282/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.7923 - loss: 0.5247 - val_accuracy: 0.7865 - val_loss: 0.5192\n",
      "Epoch 283/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.7833 - loss: 0.5217 - val_accuracy: 0.7936 - val_loss: 0.5094\n",
      "Epoch 284/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7934 - loss: 0.5077 - val_accuracy: 0.7854 - val_loss: 0.5218\n",
      "Epoch 285/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7902 - loss: 0.5141 - val_accuracy: 0.7877 - val_loss: 0.5171\n",
      "Epoch 286/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.7869 - loss: 0.5167 - val_accuracy: 0.7869 - val_loss: 0.5188\n",
      "Epoch 287/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.7874 - loss: 0.5162 - val_accuracy: 0.7988 - val_loss: 0.5092\n",
      "Epoch 288/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.7904 - loss: 0.5107 - val_accuracy: 0.7928 - val_loss: 0.5099\n",
      "Epoch 289/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.7939 - loss: 0.5051 - val_accuracy: 0.7938 - val_loss: 0.5079\n",
      "Epoch 290/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.7935 - loss: 0.5065 - val_accuracy: 0.7941 - val_loss: 0.5086\n",
      "Epoch 291/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7982 - loss: 0.5002 - val_accuracy: 0.7870 - val_loss: 0.5179\n",
      "Epoch 292/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.7852 - loss: 0.5221 - val_accuracy: 0.7939 - val_loss: 0.5102\n",
      "Epoch 293/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7936 - loss: 0.5065 - val_accuracy: 0.7882 - val_loss: 0.5134\n",
      "Epoch 294/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7896 - loss: 0.5181 - val_accuracy: 0.7917 - val_loss: 0.5133\n",
      "Epoch 295/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.7921 - loss: 0.5156 - val_accuracy: 0.7865 - val_loss: 0.5187\n",
      "Epoch 296/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.7898 - loss: 0.5160 - val_accuracy: 0.7936 - val_loss: 0.5072\n",
      "Epoch 297/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7943 - loss: 0.5061 - val_accuracy: 0.7936 - val_loss: 0.5088\n",
      "Epoch 298/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.7970 - loss: 0.5034 - val_accuracy: 0.7909 - val_loss: 0.5133\n",
      "Epoch 299/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.7896 - loss: 0.5134 - val_accuracy: 0.7873 - val_loss: 0.5187\n",
      "Epoch 300/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7902 - loss: 0.5127 - val_accuracy: 0.7943 - val_loss: 0.6090\n",
      "Epoch 301/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.7904 - loss: 0.5122 - val_accuracy: 0.7920 - val_loss: 0.5104\n",
      "Epoch 302/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.7916 - loss: 0.5088 - val_accuracy: 0.7848 - val_loss: 0.5440\n",
      "Epoch 303/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7885 - loss: 0.5167 - val_accuracy: 0.7903 - val_loss: 0.5170\n",
      "Epoch 304/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7894 - loss: 7.0166 - val_accuracy: 0.7877 - val_loss: 0.5185\n",
      "Epoch 305/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.7911 - loss: 0.5414 - val_accuracy: 0.7939 - val_loss: 0.5101\n",
      "Epoch 306/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.7960 - loss: 0.5032 - val_accuracy: 0.7951 - val_loss: 0.5047\n",
      "Epoch 307/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7914 - loss: 0.5099 - val_accuracy: 0.7857 - val_loss: 0.5191\n",
      "Epoch 308/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7926 - loss: 0.5078 - val_accuracy: 0.7930 - val_loss: 0.5084\n",
      "Epoch 309/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7928 - loss: 0.5086 - val_accuracy: 0.7911 - val_loss: 0.5133\n",
      "Epoch 310/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7913 - loss: 0.5108 - val_accuracy: 0.7965 - val_loss: 0.5042\n",
      "Epoch 311/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.7927 - loss: 0.5069 - val_accuracy: 0.7929 - val_loss: 0.5142\n",
      "Epoch 312/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.7946 - loss: 0.5091 - val_accuracy: 0.7882 - val_loss: 0.5164\n",
      "Epoch 313/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.7845 - loss: 0.5197 - val_accuracy: 0.7920 - val_loss: 0.5103\n",
      "Epoch 314/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7884 - loss: 0.5176 - val_accuracy: 0.7908 - val_loss: 0.5128\n",
      "Epoch 315/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - accuracy: 0.7897 - loss: 0.5136 - val_accuracy: 0.7930 - val_loss: 0.5145\n",
      "Epoch 316/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.7940 - loss: 0.5060 - val_accuracy: 0.7914 - val_loss: 0.5168\n",
      "Epoch 317/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - accuracy: 0.7912 - loss: 0.5115 - val_accuracy: 0.7917 - val_loss: 0.5094\n",
      "Epoch 318/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.7933 - loss: 0.5080 - val_accuracy: 0.7885 - val_loss: 0.5165\n",
      "Epoch 319/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.7919 - loss: 0.5091 - val_accuracy: 0.8028 - val_loss: 0.4962\n",
      "Epoch 320/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.7982 - loss: 0.5506 - val_accuracy: 0.7928 - val_loss: 0.5103\n",
      "Epoch 321/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7942 - loss: 0.5053 - val_accuracy: 0.7922 - val_loss: 0.5089\n",
      "Epoch 322/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.7900 - loss: 0.5149 - val_accuracy: 0.7962 - val_loss: 0.5041\n",
      "Epoch 323/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.7946 - loss: 0.5056 - val_accuracy: 0.7956 - val_loss: 0.5015\n",
      "Epoch 324/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7957 - loss: 0.6704 - val_accuracy: 0.7857 - val_loss: 0.5212\n",
      "Epoch 325/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.7880 - loss: 0.5162 - val_accuracy: 0.7908 - val_loss: 0.5143\n",
      "Epoch 326/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.7924 - loss: 0.5089 - val_accuracy: 0.7941 - val_loss: 0.5074\n",
      "Epoch 327/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7974 - loss: 0.5039 - val_accuracy: 0.7919 - val_loss: 0.5137\n",
      "Epoch 328/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.7857 - loss: 0.5190 - val_accuracy: 0.7870 - val_loss: 0.5199\n",
      "Epoch 329/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.7831 - loss: 0.5218 - val_accuracy: 0.7892 - val_loss: 0.5167\n",
      "Epoch 330/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.7934 - loss: 0.5085 - val_accuracy: 0.7946 - val_loss: 0.5148\n",
      "Epoch 331/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 0.7887 - loss: 0.5149 - val_accuracy: 0.7922 - val_loss: 0.5094\n",
      "Epoch 332/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7933 - loss: 0.5057 - val_accuracy: 0.7918 - val_loss: 0.5096\n",
      "Epoch 333/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7968 - loss: 0.5020 - val_accuracy: 0.7960 - val_loss: 0.4883\n",
      "Epoch 334/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.7913 - loss: 0.5116 - val_accuracy: 0.7871 - val_loss: 0.5178\n",
      "Epoch 335/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7850 - loss: 0.5299 - val_accuracy: 0.7853 - val_loss: 0.5236\n",
      "Epoch 336/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.7843 - loss: 0.5224 - val_accuracy: 0.7889 - val_loss: 0.5154\n",
      "Epoch 337/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7891 - loss: 0.5168 - val_accuracy: 0.7901 - val_loss: 0.5145\n",
      "Epoch 338/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7920 - loss: 0.5126 - val_accuracy: 0.7936 - val_loss: 0.5085\n",
      "Epoch 339/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.7907 - loss: 0.5103 - val_accuracy: 0.7889 - val_loss: 0.5157\n",
      "Epoch 340/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7914 - loss: 0.5130 - val_accuracy: 0.7871 - val_loss: 0.5186\n",
      "Epoch 341/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.7902 - loss: 0.5151 - val_accuracy: 0.7874 - val_loss: 0.5174\n",
      "Epoch 342/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.7921 - loss: 0.5128 - val_accuracy: 0.7881 - val_loss: 0.5165\n",
      "Epoch 343/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7876 - loss: 0.5150 - val_accuracy: 0.7930 - val_loss: 0.5093\n",
      "Epoch 344/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.7969 - loss: 0.5022 - val_accuracy: 0.7873 - val_loss: 0.5181\n",
      "Epoch 345/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7847 - loss: 0.5198 - val_accuracy: 0.7922 - val_loss: 0.5181\n",
      "Epoch 346/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7940 - loss: 0.5116 - val_accuracy: 0.7911 - val_loss: 0.5086\n",
      "Epoch 347/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530us/step - accuracy: 0.7933 - loss: 0.5081 - val_accuracy: 0.7904 - val_loss: 0.5135\n",
      "Epoch 348/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.7919 - loss: 0.5093 - val_accuracy: 0.7870 - val_loss: 0.5184\n",
      "Epoch 349/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.7856 - loss: 0.5276 - val_accuracy: 0.7848 - val_loss: 0.5223\n",
      "Epoch 350/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7815 - loss: 0.5246 - val_accuracy: 0.7862 - val_loss: 0.5192\n",
      "Epoch 351/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.7848 - loss: 0.5202 - val_accuracy: 0.7893 - val_loss: 0.5129\n",
      "Epoch 352/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - accuracy: 0.7899 - loss: 0.5161 - val_accuracy: 0.7895 - val_loss: 0.5157\n",
      "Epoch 353/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.7935 - loss: 0.5125 - val_accuracy: 0.7879 - val_loss: 0.5184\n",
      "Epoch 354/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7975 - loss: 0.5022 - val_accuracy: 0.7882 - val_loss: 0.5166\n",
      "Epoch 355/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.7941 - loss: 0.5070 - val_accuracy: 0.7943 - val_loss: 0.5066\n",
      "Epoch 356/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7965 - loss: 0.5031 - val_accuracy: 0.7990 - val_loss: 0.5010\n",
      "Epoch 357/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.7834 - loss: 0.5242 - val_accuracy: 0.7876 - val_loss: 0.5184\n",
      "Epoch 358/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.7878 - loss: 0.5158 - val_accuracy: 0.7874 - val_loss: 0.5197\n",
      "Epoch 359/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7890 - loss: 0.5144 - val_accuracy: 0.7881 - val_loss: 0.5158\n",
      "Epoch 360/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.7887 - loss: 0.5141 - val_accuracy: 0.7880 - val_loss: 0.5172\n",
      "Epoch 361/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.7858 - loss: 0.5180 - val_accuracy: 0.7976 - val_loss: 0.4998\n",
      "Epoch 362/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.7928 - loss: 0.5092 - val_accuracy: 0.7904 - val_loss: 0.5127\n",
      "Epoch 363/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.7950 - loss: 0.5056 - val_accuracy: 0.7885 - val_loss: 0.5164\n",
      "Epoch 364/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7924 - loss: 0.5126 - val_accuracy: 0.7880 - val_loss: 0.5165\n",
      "Epoch 365/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.7883 - loss: 0.5147 - val_accuracy: 0.7879 - val_loss: 0.5164\n",
      "Epoch 366/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7887 - loss: 0.5136 - val_accuracy: 0.7875 - val_loss: 0.5165\n",
      "Epoch 367/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7848 - loss: 0.5196 - val_accuracy: 0.7908 - val_loss: 0.5148\n",
      "Epoch 368/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.7913 - loss: 0.5115 - val_accuracy: 0.7930 - val_loss: 0.5115\n",
      "Epoch 369/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7900 - loss: 0.5133 - val_accuracy: 0.7940 - val_loss: 0.5077\n",
      "Epoch 370/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.7889 - loss: 0.5135 - val_accuracy: 0.7940 - val_loss: 0.5091\n",
      "Epoch 371/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7915 - loss: 0.5098 - val_accuracy: 0.7889 - val_loss: 0.5175\n",
      "Epoch 372/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.7978 - loss: 0.5021 - val_accuracy: 0.7988 - val_loss: 0.5026\n",
      "Epoch 373/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.7856 - loss: 0.5229 - val_accuracy: 0.7911 - val_loss: 0.5095\n",
      "Epoch 374/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.7868 - loss: 0.5160 - val_accuracy: 0.7886 - val_loss: 0.5170\n",
      "Epoch 375/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.7918 - loss: 0.5120 - val_accuracy: 0.7904 - val_loss: 0.5143\n",
      "Epoch 376/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7898 - loss: 0.5147 - val_accuracy: 0.7928 - val_loss: 0.5089\n",
      "Epoch 377/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7915 - loss: 0.5191 - val_accuracy: 0.7923 - val_loss: 0.5111\n",
      "Epoch 378/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.7939 - loss: 0.5078 - val_accuracy: 0.7936 - val_loss: 0.5058\n",
      "Epoch 379/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.7981 - loss: 0.5021 - val_accuracy: 0.7864 - val_loss: 0.5192\n",
      "Epoch 380/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7904 - loss: 0.5124 - val_accuracy: 0.7918 - val_loss: 0.5160\n",
      "Epoch 381/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.7881 - loss: 0.6143 - val_accuracy: 0.7897 - val_loss: 0.5129\n",
      "Epoch 382/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7919 - loss: 0.5099 - val_accuracy: 0.7907 - val_loss: 0.5141\n",
      "Epoch 383/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.7972 - loss: 0.5025 - val_accuracy: 0.7895 - val_loss: 0.5152\n",
      "Epoch 384/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7900 - loss: 0.5116 - val_accuracy: 0.7898 - val_loss: 0.5136\n",
      "Epoch 385/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7938 - loss: 0.5066 - val_accuracy: 0.7919 - val_loss: 0.5116\n",
      "Epoch 386/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.7890 - loss: 0.5488 - val_accuracy: 0.7978 - val_loss: 0.5033\n",
      "Epoch 387/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.7869 - loss: 0.5178 - val_accuracy: 0.7918 - val_loss: 0.5155\n",
      "Epoch 388/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7954 - loss: 0.5053 - val_accuracy: 0.7941 - val_loss: 0.5124\n",
      "Epoch 389/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.7887 - loss: 0.6572 - val_accuracy: 0.7889 - val_loss: 0.5161\n",
      "Epoch 390/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.7889 - loss: 0.5167 - val_accuracy: 0.7945 - val_loss: 0.5033\n",
      "Epoch 391/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7987 - loss: 0.5030 - val_accuracy: 0.7842 - val_loss: 0.5231\n",
      "Epoch 392/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.7878 - loss: 0.5161 - val_accuracy: 0.7887 - val_loss: 0.5180\n",
      "Epoch 393/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.7856 - loss: 0.5383 - val_accuracy: 0.7877 - val_loss: 0.5174\n",
      "Epoch 394/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.7902 - loss: 0.5125 - val_accuracy: 0.7908 - val_loss: 0.5143\n",
      "Epoch 395/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.7911 - loss: 0.5112 - val_accuracy: 0.7941 - val_loss: 0.5074\n",
      "Epoch 396/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7931 - loss: 0.5069 - val_accuracy: 0.7924 - val_loss: 0.5096\n",
      "Epoch 397/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.7921 - loss: 0.5126 - val_accuracy: 0.7881 - val_loss: 0.5175\n",
      "Epoch 398/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7893 - loss: 0.5133 - val_accuracy: 0.7898 - val_loss: 0.5142\n",
      "Epoch 399/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.7921 - loss: 0.5136 - val_accuracy: 0.7891 - val_loss: 0.5160\n",
      "Epoch 400/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7904 - loss: 0.5136 - val_accuracy: 0.7876 - val_loss: 0.5181\n",
      "Epoch 401/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.7826 - loss: 0.5245 - val_accuracy: 0.7908 - val_loss: 0.5133\n",
      "Epoch 402/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7890 - loss: 0.5253 - val_accuracy: 0.7885 - val_loss: 0.5165\n",
      "Epoch 403/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.7912 - loss: 0.8845 - val_accuracy: 0.7911 - val_loss: 1.1050\n",
      "Epoch 404/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7949 - loss: 0.6251 - val_accuracy: 0.7889 - val_loss: 0.5145\n",
      "Epoch 405/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.7941 - loss: 0.5323 - val_accuracy: 0.7884 - val_loss: 0.5156\n",
      "Epoch 406/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7864 - loss: 0.5175 - val_accuracy: 0.7925 - val_loss: 0.5085\n",
      "Epoch 407/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.7900 - loss: 0.5464 - val_accuracy: 0.7917 - val_loss: 0.5145\n",
      "Epoch 408/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7877 - loss: 0.5152 - val_accuracy: 0.7936 - val_loss: 0.5091\n",
      "Epoch 409/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.7962 - loss: 0.5032 - val_accuracy: 0.7919 - val_loss: 0.5164\n",
      "Epoch 410/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.7912 - loss: 0.5108 - val_accuracy: 0.7932 - val_loss: 0.5119\n",
      "Epoch 411/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.7969 - loss: 0.5041 - val_accuracy: 0.7929 - val_loss: 0.5136\n",
      "Epoch 412/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.7904 - loss: 0.5127 - val_accuracy: 0.7906 - val_loss: 0.5132\n",
      "Epoch 413/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.7922 - loss: 0.5097 - val_accuracy: 0.7877 - val_loss: 0.5168\n",
      "Epoch 414/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7869 - loss: 0.5172 - val_accuracy: 0.7892 - val_loss: 0.5176\n",
      "Epoch 415/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7874 - loss: 0.5181 - val_accuracy: 0.7909 - val_loss: 0.5148\n",
      "Epoch 416/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.7917 - loss: 0.5102 - val_accuracy: 0.7909 - val_loss: 0.5129\n",
      "Epoch 417/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7915 - loss: 0.5123 - val_accuracy: 0.7873 - val_loss: 0.5193\n",
      "Epoch 418/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - accuracy: 0.7826 - loss: 0.5237 - val_accuracy: 0.7876 - val_loss: 0.5193\n",
      "Epoch 419/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.7892 - loss: 0.5151 - val_accuracy: 0.7871 - val_loss: 0.5172\n",
      "Epoch 420/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.7892 - loss: 0.5130 - val_accuracy: 0.7903 - val_loss: 0.5148\n",
      "Epoch 421/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 0.7942 - loss: 0.5070 - val_accuracy: 0.7923 - val_loss: 0.5119\n",
      "Epoch 422/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7890 - loss: 0.5147 - val_accuracy: 0.7897 - val_loss: 0.5118\n",
      "Epoch 423/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7908 - loss: 0.5109 - val_accuracy: 0.7898 - val_loss: 0.5129\n",
      "Epoch 424/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7931 - loss: 0.5079 - val_accuracy: 0.7868 - val_loss: 0.5187\n",
      "Epoch 425/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.7883 - loss: 0.5156 - val_accuracy: 0.7902 - val_loss: 0.5131\n",
      "Epoch 426/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.7899 - loss: 0.5138 - val_accuracy: 0.7896 - val_loss: 0.5167\n",
      "Epoch 427/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7863 - loss: 0.5194 - val_accuracy: 0.7890 - val_loss: 0.5161\n",
      "Epoch 428/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7936 - loss: 0.5095 - val_accuracy: 0.7904 - val_loss: 0.5137\n",
      "Epoch 429/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7910 - loss: 0.5117 - val_accuracy: 0.7934 - val_loss: 0.5134\n",
      "Epoch 430/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.7929 - loss: 0.5091 - val_accuracy: 0.7927 - val_loss: 0.5116\n",
      "Epoch 431/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.7919 - loss: 0.5158 - val_accuracy: 0.7885 - val_loss: 0.5155\n",
      "Epoch 432/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7886 - loss: 0.5519 - val_accuracy: 0.7907 - val_loss: 0.5134\n",
      "Epoch 433/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.7838 - loss: 0.5281 - val_accuracy: 0.7909 - val_loss: 0.5132\n",
      "Epoch 434/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7924 - loss: 0.5090 - val_accuracy: 0.7930 - val_loss: 0.5100\n",
      "Epoch 435/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.7916 - loss: 0.5097 - val_accuracy: 0.7957 - val_loss: 0.5045\n",
      "Epoch 436/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.7921 - loss: 0.5074 - val_accuracy: 0.7903 - val_loss: 0.5080\n",
      "Epoch 437/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.7850 - loss: 0.5185 - val_accuracy: 0.7935 - val_loss: 0.5084\n",
      "Epoch 438/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7946 - loss: 0.5051 - val_accuracy: 0.7934 - val_loss: 0.5092\n",
      "Epoch 439/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.7967 - loss: 0.5008 - val_accuracy: 0.7903 - val_loss: 0.5130\n",
      "Epoch 440/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7954 - loss: 0.5049 - val_accuracy: 0.7889 - val_loss: 0.5171\n",
      "Epoch 441/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.7898 - loss: 0.5136 - val_accuracy: 0.7941 - val_loss: 0.5140\n",
      "Epoch 442/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.7930 - loss: 0.5088 - val_accuracy: 0.7865 - val_loss: 0.5224\n",
      "Epoch 443/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.7903 - loss: 0.5202 - val_accuracy: 0.7927 - val_loss: 0.5134\n",
      "Epoch 444/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.7921 - loss: 0.5116 - val_accuracy: 0.7930 - val_loss: 0.5119\n",
      "Epoch 445/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.7847 - loss: 0.5270 - val_accuracy: 0.7932 - val_loss: 0.5124\n",
      "Epoch 446/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.7888 - loss: 0.5137 - val_accuracy: 0.7865 - val_loss: 0.5196\n",
      "Epoch 447/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7915 - loss: 0.5108 - val_accuracy: 0.7877 - val_loss: 0.5163\n",
      "Epoch 448/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7900 - loss: 0.5146 - val_accuracy: 0.7906 - val_loss: 0.5146\n",
      "Epoch 449/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.7863 - loss: 0.5222 - val_accuracy: 0.7873 - val_loss: 0.5188\n",
      "Epoch 450/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.7851 - loss: 0.5189 - val_accuracy: 0.7898 - val_loss: 0.5163\n",
      "Epoch 451/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7885 - loss: 0.5145 - val_accuracy: 0.7930 - val_loss: 0.5097\n",
      "Epoch 452/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7892 - loss: 0.5128 - val_accuracy: 0.7911 - val_loss: 0.5183\n",
      "Epoch 453/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.7941 - loss: 0.5076 - val_accuracy: 0.7885 - val_loss: 0.5175\n",
      "Epoch 454/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.7878 - loss: 0.5170 - val_accuracy: 0.7914 - val_loss: 0.5140\n",
      "Epoch 455/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.7902 - loss: 0.5114 - val_accuracy: 0.7913 - val_loss: 0.5157\n",
      "Epoch 456/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.7972 - loss: 0.5030 - val_accuracy: 0.7922 - val_loss: 0.5127\n",
      "Epoch 457/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.7938 - loss: 0.5059 - val_accuracy: 0.7928 - val_loss: 0.5111\n",
      "Epoch 458/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.7914 - loss: 0.5106 - val_accuracy: 0.7932 - val_loss: 0.5125\n",
      "Epoch 459/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.7924 - loss: 0.5088 - val_accuracy: 0.7935 - val_loss: 0.5121\n",
      "Epoch 460/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.7939 - loss: 0.5065 - val_accuracy: 0.7951 - val_loss: 0.5080\n",
      "Epoch 461/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.7941 - loss: 0.5061 - val_accuracy: 0.7881 - val_loss: 0.5174\n",
      "Epoch 462/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7931 - loss: 0.5103 - val_accuracy: 0.7951 - val_loss: 0.5051\n",
      "Epoch 463/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.7929 - loss: 0.5091 - val_accuracy: 0.7890 - val_loss: 0.5142\n",
      "Epoch 464/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.7891 - loss: 0.5164 - val_accuracy: 0.7930 - val_loss: 0.5135\n",
      "Epoch 465/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.7893 - loss: 0.5122 - val_accuracy: 0.7927 - val_loss: 0.5139\n",
      "Epoch 466/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.7946 - loss: 0.5074 - val_accuracy: 0.7893 - val_loss: 0.5133\n",
      "Epoch 467/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.7912 - loss: 0.5101 - val_accuracy: 0.7917 - val_loss: 0.5139\n",
      "Epoch 468/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.7909 - loss: 0.5131 - val_accuracy: 0.7936 - val_loss: 0.5148\n",
      "Epoch 469/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7930 - loss: 0.5091 - val_accuracy: 0.7925 - val_loss: 0.5145\n",
      "Epoch 470/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.7948 - loss: 0.5056 - val_accuracy: 0.7900 - val_loss: 0.5156\n",
      "Epoch 471/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.7884 - loss: 0.5140 - val_accuracy: 0.7893 - val_loss: 0.5160\n",
      "Epoch 472/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7898 - loss: 0.5159 - val_accuracy: 0.7873 - val_loss: 0.5184\n",
      "Epoch 473/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.7888 - loss: 0.5140 - val_accuracy: 0.7897 - val_loss: 0.5170\n",
      "Epoch 474/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7924 - loss: 0.5102 - val_accuracy: 0.7959 - val_loss: 0.5056\n",
      "Epoch 475/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.7935 - loss: 0.5268 - val_accuracy: 0.7914 - val_loss: 0.5125\n",
      "Epoch 476/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7930 - loss: 0.5294 - val_accuracy: 0.7895 - val_loss: 0.5206\n",
      "Epoch 477/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.7836 - loss: 0.5233 - val_accuracy: 0.7947 - val_loss: 0.5133\n",
      "Epoch 478/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.7848 - loss: 0.5219 - val_accuracy: 0.7879 - val_loss: 0.5175\n",
      "Epoch 479/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.7900 - loss: 0.5194 - val_accuracy: 0.7877 - val_loss: 0.5185\n",
      "Epoch 480/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 0.7875 - loss: 0.5205 - val_accuracy: 0.7875 - val_loss: 0.5184\n",
      "Epoch 481/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7843 - loss: 0.5218 - val_accuracy: 0.7895 - val_loss: 0.5353\n",
      "Epoch 482/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.7861 - loss: 0.5234 - val_accuracy: 0.7929 - val_loss: 0.5126\n",
      "Epoch 483/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 0.7952 - loss: 0.5059 - val_accuracy: 0.7898 - val_loss: 0.5139\n",
      "Epoch 484/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7915 - loss: 0.5100 - val_accuracy: 0.7929 - val_loss: 0.5122\n",
      "Epoch 485/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.7970 - loss: 0.5018 - val_accuracy: 0.7947 - val_loss: 0.5045\n",
      "Epoch 486/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.7898 - loss: 0.5119 - val_accuracy: 0.7891 - val_loss: 0.8653\n",
      "Epoch 487/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.7937 - loss: 0.5109 - val_accuracy: 0.7876 - val_loss: 0.5177\n",
      "Epoch 488/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7908 - loss: 0.5688 - val_accuracy: 0.7893 - val_loss: 0.5194\n",
      "Epoch 489/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.7856 - loss: 0.5194 - val_accuracy: 0.7907 - val_loss: 0.5135\n",
      "Epoch 490/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7927 - loss: 0.5118 - val_accuracy: 0.7909 - val_loss: 0.5164\n",
      "Epoch 491/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.7912 - loss: 0.5114 - val_accuracy: 0.7911 - val_loss: 0.5108\n",
      "Epoch 492/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7896 - loss: 0.5132 - val_accuracy: 0.7889 - val_loss: 0.5181\n",
      "Epoch 493/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.7893 - loss: 0.5129 - val_accuracy: 0.7929 - val_loss: 0.5138\n",
      "Epoch 494/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7898 - loss: 0.5136 - val_accuracy: 0.7943 - val_loss: 0.5100\n",
      "Epoch 495/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.7904 - loss: 0.5118 - val_accuracy: 0.7945 - val_loss: 0.5117\n",
      "Epoch 496/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.7839 - loss: 0.5271 - val_accuracy: 0.7864 - val_loss: 0.5221\n",
      "Epoch 497/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7879 - loss: 0.5157 - val_accuracy: 0.7884 - val_loss: 0.5187\n",
      "Epoch 498/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.7908 - loss: 0.5121 - val_accuracy: 0.7879 - val_loss: 0.5180\n",
      "Epoch 499/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7888 - loss: 0.5147 - val_accuracy: 0.7900 - val_loss: 0.5186\n",
      "Epoch 500/500\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.7912 - loss: 0.5127 - val_accuracy: 0.7870 - val_loss: 0.5185\n"
     ]
    }
   ],
   "source": [
    "# Trainin NN is quite fast so we can try to do more epochs to see if we can get better results\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7870120304443898\n",
      "\n",
      "Confusion Matrix: \n",
      " [[6365    4]\n",
      " [1731   46]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      6369\n",
      "           1       0.92      0.03      0.05      1777\n",
      "\n",
      "    accuracy                           0.79      8146\n",
      "   macro avg       0.85      0.51      0.47      8146\n",
      "weighted avg       0.82      0.79      0.70      8146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding more epochs did not improve the model so we will stick with 100 epochs\n",
    "# Predicting on test data\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Converting the predicted values to binary\n",
    "y_pred = [1 if i>=0.5 else 0 for i in y_pred]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Saving the model\n",
    "model.save('../models/credit_risk_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model has an accuracy of 0.79 which is quite good. We can use this model to predict the loan status of new customers.\n",
    "# The precision and recall for both classes is also quite good.\n",
    "# We can try to use this model to predict the loan status of new customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
